{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc72ed9",
   "metadata": {},
   "source": [
    "- https://platform.openai.com/docs/models/overview\n",
    "\n",
    "- /completions endpoint provides the completion for a single prompt and takes a single string as an input.\n",
    "- /chat/completions provides the responses for a given dialog and requires the input in a specific format corresponding to the message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56328bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from decouple import config\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a220cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253a308c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['babbage',\n",
       " 'text-davinci-003',\n",
       " 'davinci',\n",
       " 'text-davinci-edit-001',\n",
       " 'babbage-code-search-code',\n",
       " 'text-similarity-babbage-001',\n",
       " 'code-davinci-edit-001',\n",
       " 'ada',\n",
       " 'babbage-code-search-text',\n",
       " 'babbage-similarity',\n",
       " 'gpt-3.5-turbo-16k-0613',\n",
       " 'code-search-babbage-text-001',\n",
       " 'text-curie-001',\n",
       " 'gpt-3.5-turbo-0301',\n",
       " 'gpt-3.5-turbo-16k',\n",
       " 'code-search-babbage-code-001',\n",
       " 'text-ada-001',\n",
       " 'text-similarity-ada-001',\n",
       " 'text-davinci-002',\n",
       " 'curie-instruct-beta',\n",
       " 'ada-code-search-code',\n",
       " 'ada-similarity',\n",
       " 'code-search-ada-text-001',\n",
       " 'text-search-ada-query-001',\n",
       " 'davinci-search-document',\n",
       " 'whisper-1',\n",
       " 'ada-code-search-text',\n",
       " 'text-search-ada-doc-001',\n",
       " 'davinci-instruct-beta',\n",
       " 'text-similarity-curie-001',\n",
       " 'code-search-ada-code-001',\n",
       " 'ada-search-query',\n",
       " 'text-search-davinci-query-001',\n",
       " 'curie-search-query',\n",
       " 'davinci-search-query',\n",
       " 'babbage-search-document',\n",
       " 'ada-search-document',\n",
       " 'text-search-curie-query-001',\n",
       " 'text-babbage-001',\n",
       " 'text-search-babbage-doc-001',\n",
       " 'curie-search-document',\n",
       " 'text-davinci-001',\n",
       " 'text-search-curie-doc-001',\n",
       " 'babbage-search-query',\n",
       " 'text-search-davinci-doc-001',\n",
       " 'text-search-babbage-query-001',\n",
       " 'curie-similarity',\n",
       " 'text-embedding-ada-002',\n",
       " 'curie',\n",
       " 'text-similarity-davinci-001',\n",
       " 'gpt-3.5-turbo-0613',\n",
       " 'davinci-similarity',\n",
       " 'gpt-3.5-turbo']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = []\n",
    "for model in openai.Model.list()['data']:\n",
    "    model_names.append(model['id'])\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1df2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6499fe6",
   "metadata": {},
   "source": [
    "## Use GPT to Respond to Customer Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6460170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reply(review):\n",
    "    '''\n",
    "    temperature: This parameter controls the randomness of the generated text. A higher temperature (e.g., 0.7) makes the output more diverse and creative, while a lower temperature (e.g., 0.2) makes it more focused and deterministic.\n",
    "    max_tokens: This parameter specifies the maximum number of tokens (words or subwords) that the language model will generate in its response. Setting this value limits the length of the output.\n",
    "    frequency_penalty: This parameter is used to penalize the language model from generating repetitive phrases. A value of 0 means no penalty, while higher values (e.g., 1.0) increase the penalty.\n",
    "    presence_penalty: This parameter is used to penalize the language model from overusing specific words or phrases. A value of 0 means no penalty, while higher values (e.g., 1.0) increase the penalty.\n",
    "    '''\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=f\"This is a restaurant review replier bot. If the customer has any concerns address them.\\n\\nReview:{review}\\n\\nReply:\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=100,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return response.choices[0].get('text', 'No reply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d481b70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for your kind words - we're glad you enjoyed your biryani!\n"
     ]
    }
   ],
   "source": [
    "review = '''\n",
    "The biryani here is absolutely delicious! The flavorful spices and tender meat make it a true delight. Must try!\n",
    "'''\n",
    "\n",
    "reply = generate_reply(review)\n",
    "print(reply.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f4006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbfb3cb5",
   "metadata": {},
   "source": [
    "## Use GPT to get Plot based Movie Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "318fcf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_based_movies_shows_recommendations(movie_name):\n",
    "    \n",
    "    result = ''\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        # system message that sets the context for the conversation with the language model. It informs the model about its capabilities and what is expected from it          \n",
    "        messages = [        \n",
    "                {\"role\": \"system\", \"content\": \"You have knowledge about movies, shows, web series across all languages. You can recommend movies/shows from the same language. If you're unable to identify similar content, respond only with 'Sorry unable to identify the genre, plot or similar content'.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Please provide 5 content recommendations similar to '\" + movie_name + \"' based on the plot. The output format should be 'Plot Based Similar Content: <content_1>, <content_2>, <content_3>, <content_4>, <content_5>'. Additionally, please provide the primary genre of '\" + movie_name + \"' in the format 'Primary Genre: <genre_name_here>'.\"},\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for choice in response.choices:\n",
    "            result += choice.message.content\n",
    "\n",
    "        if \"sorry unable\" in result.lower():\n",
    "            result = \"Could not identify the content!!\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        result = \"Request Failed!!\"\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ebf7f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Genre: Comedy, Drama\n",
      "\n",
      "Plot Based Similar Content: \n",
      "1. Taare Zameen Par\n",
      "2. Rang De Basanti\n",
      "3. PK\n",
      "4. Wake Up Sid\n",
      "5. Student of the Year\n"
     ]
    }
   ],
   "source": [
    "result = get_plot_based_movies_shows_recommendations(\"3 Idiots\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c4ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
